{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "driven-archives",
   "metadata": {},
   "source": [
    "# RLC - Reptile pretraining\n",
    "Notebook to run experiments on the RLC circuit dataset.\n",
    "\n",
    "Before running this notebook, you need to run the pretraining run. To do so, execute the following command from the repository root directory:\n",
    "`python tsfewshot/run_scheduler.py train --directory experiments/nl-rlc/configs/ --runs-per-gpu 4 --gpu-ids 0` or `python tsfewshot/run.py train --config-file experiments/nl-rlc/configs/reptile-config.yml --gpu 0`\n",
    "\n",
    "The first will run all config files in the specified directory, with 4 runs in parallel on GPU 0, the latter only the Reptile pretraining run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "backed-syndication",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pickle\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "from importlib import reload\n",
    "import logging\n",
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', datefmt='%I:%M:%S')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append('../..')\n",
    "from tsfewshot.config import Config\n",
    "from tsfewshot import plot, analyses\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "DEVICE = 'cuda:0'\n",
    "SUPPORT_SIZES = [10, 20, 30, 50, 70, 100]\n",
    "QUERY_SIZE = 2000\n",
    "\n",
    "CODE_DIR = Path('../..')\n",
    "DATA_DIR = 'experiments/nl-rlc/data/rlc_dataset-resistor_range1_14-capacitor_range100_800-inductor_range20_140'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "permanent-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the run directories from the meta-training phase\n",
    "RUN = Path('runs/reptile/rlc-ode-3trtraj-reptile-50support10batch5steplr0.001innerlr0.001-finetune5-seed0').resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tasks on which we will generate the finetuning trajectories that\n",
    "# will be used to calculate the preconditioning matrix\n",
    "finetune_tasks = sorted(f'val/{d.name}' for d in (Path(DATA_DIR) / 'val').glob('*.npy'))\n",
    "len(finetune_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-entry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create finetuning configurations for each of the above finetune_tasks\n",
    "n_ft_tasks = len(finetune_tasks)\n",
    "finetune_lrs = [5e-6]\n",
    "# generate finetune configs\n",
    "for run in [RUN]:\n",
    "    best_epoch_file = run / 'best_epoch.txt'\n",
    "    if not best_epoch_file.exists():\n",
    "        print(f'best-epoch file {best_epoch_file} not found.')\n",
    "        continue\n",
    "    with best_epoch_file.open('r') as fp:\n",
    "        epoch = int(fp.read())\n",
    "    cfg = Config(run / 'config.yml')\n",
    "    for flr in finetune_lrs:\n",
    "        finetune_cfg = f\"\"\"\n",
    "experiment_name: {run.name}-adam_flr{flr}-n_fts{n_ft_tasks}-NNNN\n",
    "val_datasets: \n",
    " - VVVV#0#3\n",
    "test_datasets: \n",
    " - VVVV#3#5\n",
    "finetune_lr: {flr}\n",
    "optimizer: adam\n",
    "finetune_epochs: 30\n",
    "early_stopping_patience: 5\n",
    "eval_every: 1\n",
    "save_every: -1\n",
    "checkpoint_path: {str(run.absolute())}/model_epoch{str(epoch).zfill(3)}.p\n",
    "base_run_dir: {str(run.absolute())}\n",
    "run_dir: {str(run.absolute())}/finetune_adam_flr{flr}_n_fts{n_ft_tasks}\n",
    "finetune: false\n",
    "training_setup: supervised\n",
    "predict_last_n: 256\n",
    "seq_length: 256\n",
    "val_n_random_datasets: null\n",
    "batch_size: 16\n",
    "\"\"\"\n",
    "\n",
    "        (run / f'finetune_adam_flr{flr}_n_fts{n_ft_tasks}/configs').mkdir(exist_ok=True, parents=True)\n",
    "        print(run / f'finetune_adam_flr{flr}_n_fts{n_ft_tasks}/configs')\n",
    "        for task in finetune_tasks:\n",
    "            task_finetune_cfg = finetune_cfg.replace('VVVV', task).replace('NNNN', task.replace('/', ''))\n",
    "            with (run / f'finetune_adam_flr{flr}_n_fts{n_ft_tasks}/configs/{task.replace(\"#\", \"\").replace(\"/\", \"\")}.yml').open('w') as f:\n",
    "                f.write(task_finetune_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-norway",
   "metadata": {},
   "source": [
    "Next, you need to start the created finetuning runs. For each pretraining run, execute:\n",
    "`python tsfewshot/run_scheduler.py finetune --directory /path/to/run/finetune_adam_flr5e-6_n_fts512/configs/ --gpu-ids 0 --runs-per-gpu 5`\n",
    "(adapt gpu-ids and runs-per-gpu according to the number and size of your GPU(s)).\n",
    "\n",
    "After all runs are completed, calculate the preconditioning matrix for each support size:\n",
    "`python pca.py --base-dir /path/to/run --finetune-dirs /path/to/run/finetune_adam_flr5e-6_n_fts512/rlc* --epoch -1`.\n",
    "This will pickle the preconditioning matrix to `/path/to/run/pca/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_epochs = defaultdict(lambda: 500)\n",
    "\n",
    "eval_every = list(range(20)) + list(range(20, 501, 20))\n",
    "inner_seeds = [0]\n",
    "\n",
    "type_specs = [\n",
    "    'normal',  # SGD finetuning\n",
    "    'pca',  # our method\n",
    "]\n",
    "\n",
    "gridsearch_dir = 'optimizeFinetune'\n",
    "\n",
    "def combinations():\n",
    "    combinations = []\n",
    "    for type_spec in type_specs:\n",
    "        if 'pca' in type_spec:\n",
    "            lrs = [1e-2, 1e-3, 1e-4, 1e-5, 1e-6]  \n",
    "        elif 'normal' in type_spec:\n",
    "            lrs = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "        elif 'jfr' in type_spec:\n",
    "            lrs = [1.0] # dummy, this adaption method does not use gradient descent, hence no lr\n",
    "        for lr in lrs:\n",
    "            for support in SUPPORT_SIZES:\n",
    "                combinations.append({'support': support,\n",
    "                                     'lr': lr,\n",
    "                                     'type': type_spec,\n",
    "                                     'noise': 0.0,\n",
    "                                     'sparsity': None,\n",
    "                                     'pca_interpolate': 1.0,\n",
    "                                    })\n",
    "    return combinations\n",
    "    \n",
    "len(combinations())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create gridsearch for optimal learning rate and number of update steps during finetuning.\n",
    "new_runs = analyses.create_gridsearch_dirs(RUN,\n",
    "                                            combinations(),\n",
    "                                            gridsearch_dir,\n",
    "                                            inner_seeds,\n",
    "                                            n_trajectories=-1,\n",
    "                                            query_size=QUERY_SIZE,\n",
    "                                            ft_epochs=ft_epochs,\n",
    "                                            eval_every=eval_every,\n",
    "                                            save_predictions=True,\n",
    "                                            optimizer='sgd-squared',\n",
    "                                            val_datasets=finetune_tasks[::2], # gridsearch on half of the finetune_tasks\n",
    "                                            init_epoch=None, # uses best epoch\n",
    "                                            pca_file_path=RUN / 'pca/pca-torchcenterFalseNonecomponentspathNoneimprovedFalseusestepsNonelayerwiseFalse.p')\n",
    "\n",
    "[r.name for r in new_runs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-tuning",
   "metadata": {},
   "source": [
    "Next, run the created gridsearch configurations via:\n",
    "`python tsfewshot/run_scheduler.py eval --directory /path/to/run/optimizeFinetune/ --epoch -1 --split val --gpu-ids 0 --runs-per-gpu 5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "brazilian-evanescence",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ft_options = {}\n",
    "best_ft_epochs = {}\n",
    "gridsearch_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the gridsearch results and calculate the best learning rate and number of update steps\n",
    "# for each support size and each method.\n",
    "# For the best configuration of each support size and method, we create a final finetuning experiment\n",
    "# that we'll use to analyze the results.\n",
    "test_tasks = sorted(f'test/{d.name}' for d in (Path(DATA_DIR) / 'test').glob('*.npy'))\n",
    "new_run_dirs, best_ft_options, best_ft_epochs, gridsearch_results = \\\n",
    "    analyses.create_final_finetune_dirs([RUN],\n",
    "                                          SUPPORT_SIZES,\n",
    "                                          combinations(),\n",
    "                                          inner_seeds,\n",
    "                                          gridsearch_dir,\n",
    "                                          test_tasks,\n",
    "                                          best_ft_options=best_ft_options,\n",
    "                                          best_ft_epochs=best_ft_epochs,\n",
    "                                          n_results=256,\n",
    "                                          metric_aggregation='median',\n",
    "                                          metric_name='mse')\n",
    "[r.name for r in new_run_dirs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot.plot_gridsearch(gridsearch_results)\n",
    "_ = plt.ylim(0.0, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-simon",
   "metadata": {},
   "source": [
    "Next, run the final finetuning experiments:\n",
    "`python tsfewshot/run_scheduler.py eval --directory /path/to/run/optimizeFinetune_finalFinetune/ --epoch -1 --split test --gpu-ids 0 --runs-per-gpu 5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-plane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the result from final finetuning\n",
    "metrics = None\n",
    "metrics = analyses.get_final_metrics([RUN],\n",
    "                                     noises=[0.0],\n",
    "                                     support_sizes=SUPPORT_SIZES,\n",
    "                                     combinations=combinations(),\n",
    "                                     best_ft_options=best_ft_options,\n",
    "                                     inner_seeds=inner_seeds,\n",
    "                                     query_size=QUERY_SIZE,\n",
    "                                     n_trajectories=-1,\n",
    "                                     test_tasks=test_tasks,\n",
    "                                     gridsearch_dir=gridsearch_dir,\n",
    "                                     init_epoch=None,\n",
    "                                     metrics=metrics,\n",
    "                                     metric_name='mse',\n",
    "                                     metric_file_name='mse_rmse',\n",
    "                                     metric_aggregation='median',\n",
    "                                     n_dataset_evals = None,\n",
    "                                     no_ft_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "anticipated-looking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump results so we don't have to recalculate each time we run this notebook\n",
    "pickle.dump(metrics, (RUN / 'metrics.p').open('wb'))\n",
    "pickle.dump(best_ft_options, (RUN / 'best_ft_options.p').open('wb'))\n",
    "pickle.dump(best_ft_epochs, (RUN / 'best_ft_epochs.p').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "199de598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load metrics when re-executing the notebook, so we don't have to recalculate\n",
    "metrics = pickle.load((RUN / 'metrics_.p').open('rb'))\n",
    "best_ft_options = pickle.load((RUN / 'best_ft_options.p').open('rb'))\n",
    "best_ft_epochs = pickle.load((RUN / 'best_ft_epochs.p').open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-preview",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norms = pd.DataFrame({k: v['mse'] for k, v in metrics[0.0].items()}, dtype=float)\n",
    "df_norms.columns.names = ['support', 'type', 'seed']\n",
    "\n",
    "# results table\n",
    "display_df = df_norms.copy()\n",
    "median = display_df.median(axis=0)\n",
    "mean = display_df.mean(axis=0)\n",
    "display_df.loc[' rank'] = display_df.groupby('support', axis=1).rank(axis=1).median(axis=0)\n",
    "display_df.loc[' median'] = median\n",
    "display_df.loc[' mean'] = mean\n",
    "display(display_df.sort_index().style.background_gradient('Greens_r', axis=1).highlight_null('white'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "driven-hostel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "figsize = (7,4)\n",
    "f = plot.plot_support_vs_mse(df_norms,\n",
    "                             SUPPORT_SIZES,\n",
    "                             ranks=False,\n",
    "                             figsize=figsize,\n",
    "                             aggregation='median',\n",
    "                             title='rlc', \n",
    "                             exclude_types=[],\n",
    "                             metric_name='MSE')\n",
    "plt.ylim(0,0.1)\n",
    "f2 = plot.plot_support_vs_mse(df_norms,\n",
    "                              SUPPORT_SIZES,\n",
    "                              ranks=True,\n",
    "                              figsize=figsize,\n",
    "                              title='rlc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2dce560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_475a5_\" ><thead>    <tr>        <th class=\"index_name level0\" >support</th>        <th class=\"col_heading level0 col0\" >10</th>        <th class=\"col_heading level0 col1\" >20</th>        <th class=\"col_heading level0 col2\" >30</th>        <th class=\"col_heading level0 col3\" >50</th>        <th class=\"col_heading level0 col4\" >70</th>        <th class=\"col_heading level0 col5\" >100</th>    </tr>    <tr>        <th class=\"index_name level0\" >type</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_475a5_level0_row0\" class=\"row_heading level0 row0\" >no-finetune</th>\n",
       "                        <td id=\"T_475a5_row0_col0\" class=\"data row0 col0\" >4.947e-07</td>\n",
       "                        <td id=\"T_475a5_row0_col1\" class=\"data row0 col1\" >1.425e-11</td>\n",
       "                        <td id=\"T_475a5_row0_col2\" class=\"data row0 col2\" >1.491e-21</td>\n",
       "                        <td id=\"T_475a5_row0_col3\" class=\"data row0 col3\" >3.469e-28</td>\n",
       "                        <td id=\"T_475a5_row0_col4\" class=\"data row0 col4\" >9.894e-31</td>\n",
       "                        <td id=\"T_475a5_row0_col5\" class=\"data row0 col5\" >1.239e-30</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_475a5_level0_row1\" class=\"row_heading level0 row1\" >normal noise 0.0 </th>\n",
       "                        <td id=\"T_475a5_row1_col0\" class=\"data row1 col0\" >1.520e-07</td>\n",
       "                        <td id=\"T_475a5_row1_col1\" class=\"data row1 col1\" >8.573e-13</td>\n",
       "                        <td id=\"T_475a5_row1_col2\" class=\"data row1 col2\" >6.067e-21</td>\n",
       "                        <td id=\"T_475a5_row1_col3\" class=\"data row1 col3\" >2.597e-23</td>\n",
       "                        <td id=\"T_475a5_row1_col4\" class=\"data row1 col4\" >4.771e-23</td>\n",
       "                        <td id=\"T_475a5_row1_col5\" class=\"data row1 col5\" >3.926e-24</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_475a5_level0_row2\" class=\"row_heading level0 row2\" >pca noise 0.0 </th>\n",
       "                        <td id=\"T_475a5_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "                        <td id=\"T_475a5_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
       "                        <td id=\"T_475a5_row2_col2\" class=\"data row2 col2\" >nan</td>\n",
       "                        <td id=\"T_475a5_row2_col3\" class=\"data row2 col3\" >nan</td>\n",
       "                        <td id=\"T_475a5_row2_col4\" class=\"data row2 col4\" >nan</td>\n",
       "                        <td id=\"T_475a5_row2_col5\" class=\"data row2 col5\" >nan</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f944b54fb50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# significance test\n",
    "from scipy.stats import wilcoxon\n",
    "p = {}\n",
    "noise = 0.0\n",
    "sig_df = df_norms.groupby(['support', 'type'], axis=1).agg(lambda s: s.mean(skipna=False))\n",
    "best_typs = {support: sig_df.loc[:, support].median().idxmin(axis=1) for support in SUPPORT_SIZES}\n",
    "for support, typ in sig_df.columns:\n",
    "    if typ == f'{best_typs[support]} noise 0.0 ':\n",
    "        p[(support, typ)] = np.nan\n",
    "        continue\n",
    "    if ((sig_df.loc[:, (support, typ)] - sig_df.loc[:, (support, best_typs[support])]) == 0).all():\n",
    "        p[(support, typ)] = np.nan\n",
    "        continue\n",
    "    p[(support, typ)] = wilcoxon(sig_df.loc[:, (support, typ)], sig_df.loc[:, (support, best_typs[support])])[1]\n",
    "sig_df = pd.DataFrame(p, index=['p-value']).T\n",
    "sig_df.index.names = ['support', 'type']\n",
    "display(sig_df.reset_index().pivot(index='type', columns='support', values='p-value').style.format('{:.3e}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-basin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot eigenvalue distribution\n",
    "pca = pickle.load((RUN / 'pca/pca-torchcenterFalseNonecomponentspathNoneimprovedFalseusestepsNonelayerwiseFalse.p').open('rb'))\n",
    "eigenvalues = pca['s']**2 / (pca['u'].shape[0] - 1)\n",
    "plt.plot(eigenvalues)\n",
    "plt.ylabel('Eigenvalue')\n",
    "plt.xlabel('Component')\n",
    "plt.grid(alpha=0.6)\n",
    "plt.yscale('log')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = RUN\n",
    "finetune_dirs = list((run / f'finetune_adam_epoch{init_epoch}').glob('rlc*/'))  # TODO init_epoch\n",
    "cfg = Config(run / 'config.yml')\n",
    "plt.figure(figsize=(14,7))\n",
    "f, ax = plot.plot_deltas_rank(cfg, finetune_dirs,\n",
    "                              tols=[0],\n",
    "                              ax=plt.gca(),\n",
    "                              random_baseline=True,\n",
    "                              n_repeats=1,\n",
    "                              task_steps=1,\n",
    "                              within_task_steps=None,\n",
    "                              epoch_steps=None,\n",
    "                              use_erank=True,\n",
    "                              init_epoch=-1,\n",
    "                              plot_val_metric=False)\n",
    "plt.xscale('log')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
